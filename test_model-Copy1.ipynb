{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# needed imports\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "# deep learning library\n",
    "import keras\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Activation, Dropout, BatchNormalization, UpSampling2D, concatenate\n",
    "from keras.optimizers import Adam\n",
    "from keras import Model\n",
    "\n",
    "# plotting images\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Accessing intermediate layers\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from keras.applications import vgg16\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# numpy array containing all the classes\n",
    "class_labels = np.array((33, 34, 35, 36, 38, 39, 40, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #coding:utf8\n",
    "\n",
    "\n",
    "# class Vgg16(torch.nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(Vgg16, self).__init__()\n",
    "#         features = list(vgg16(pretrained = True).features)[:23]\n",
    "        \n",
    "#         # features的第3，8，15，22层分别是: relu1_2,relu2_2,relu3_3,relu4_3\n",
    "#         self.features = nn.ModuleList(features).eval() \n",
    "#         print(self.features)\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         results = []\n",
    "#         for ii,model in enumerate(self.features):\n",
    "#             x = model(x)\n",
    "#             if ii in {3,8,15,22}:\n",
    "#                 results.append(x)\n",
    "#         vgg_outputs = namedtuple(\"VggOutputs\", ['relu1_2', 'relu2_2', 'relu3_3', 'relu4_3'])\n",
    "#         return vgg_outputs(*results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# vgg_16 = Vgg16()\n",
    "# x_in = Input(shape=(128, 128, 3))\n",
    "# c = vgg_16.forward(x_in)[1][1]\n",
    "# c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#coding:utf8\n",
    "# THIS THING WORKS BUT WE DON'T KNOW HOW TO CONTINUE\n",
    "from keras.applications import vgg16\n",
    "\n",
    "\n",
    "class Vgg16():\n",
    "    def __init__(self):\n",
    "        self._vgg16 = vgg16.VGG16(weights='imagenet', include_top=False, input_shape = (None,None,3))\n",
    "        self.features = [l for l in self._vgg16.layers]\n",
    "        \n",
    "    def forward(self, x):\n",
    "        results = []\n",
    "        for ii,layer in enumerate(self.features):\n",
    "            x = layer(x)\n",
    "            if ii in {5,9,13,17}:\n",
    "                results.append(x)\n",
    "        vgg_outputs = namedtuple(\"VggOutputs\", ['relu_0','relu1_2', 'relu2_2', 'relu3_3'])\n",
    "        return vgg_outputs(*results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, None, None, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, None, None, 6 1792        input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, None, None, 6 36928       block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, None, None, 6 0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, None, None, 1 73856       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, None, None, 1 147584      block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, None, None, 1 0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, None, None, 2 295168      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, None, None, 2 590080      block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, None, None, 2 590080      block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, None, None, 2 0           block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, None, None, 5 1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, None, None, 5 2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, None, None, 5 2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, None, None, 5 0           block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)           (None, None, None, 5 2359808     block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)           (None, None, None, 5 2359808     block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)           (None, None, None, 5 2359808     block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)      (None, None, None, 5 0           block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, None, None, 2 1179904     block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, None, None, 2 1024        conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, None, None, 2 0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, None, None, 2 0           activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_16 (UpSampling2D) (None, None, None, 2 0           dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, None, None, 7 0           up_sampling2d_16[0][0]           \n",
      "                                                                 block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, None, None, 2 1769728     concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, None, None, 2 1024        conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, None, None, 2 0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, None, None, 2 0           activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_17 (UpSampling2D) (None, None, None, 2 0           dropout_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, None, None, 7 0           up_sampling2d_17[0][0]           \n",
      "                                                                 block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, None, None, 1 884864      concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, None, None, 1 512         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, None, None, 1 0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, None, None, 1 0           activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_18 (UpSampling2D) (None, None, None, 1 0           dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, None, None, 3 0           up_sampling2d_18[0][0]           \n",
      "                                                                 block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, None, None, 6 221248      concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, None, None, 6 256         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, None, None, 6 0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, None, None, 6 0           activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_19 (UpSampling2D) (None, None, None, 6 0           dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, None, None, 3 18464       up_sampling2d_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, None, None, 3 128         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, None, None, 3 0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, None, None, 3 0           activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_20 (UpSampling2D) (None, None, None, 3 0           dropout_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, None, None, 8 2312        up_sampling2d_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, None, None, 8 32          conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, None, None, 8 0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, None, None, 8 0           activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, None, None, 8 0           dropout_24[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 18,794,184\n",
      "Trainable params: 4,078,008\n",
      "Non-trainable params: 14,716,176\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pabloleo96/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:117: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"ac...)`\n"
     ]
    }
   ],
   "source": [
    "# since we are going to segment the image, the input should not have any dimension\n",
    "x_in = Input(shape = (None,None,3))\n",
    "\n",
    "vgg_16 = vgg16.VGG16(weights='imagenet', include_top=False,  input_tensor = x_in)\n",
    "\n",
    "for l in vgg_16.layers:\n",
    "    l.trainable = False\n",
    "\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------\n",
    "#-----------------------------------------------------------------------------------------------\n",
    "#-----------------------------------------------------------------------------------------------\n",
    "# CONV 0\n",
    "\n",
    "x = Conv2D(filters = 256,\n",
    "           kernel_size = (3,3),\n",
    "           kernel_initializer = 'he_uniform',\n",
    "           padding = 'same')(vgg_16.layers[-1].output)\n",
    "\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = Activation(activation = 'relu')(x)\n",
    "\n",
    "x = Dropout(0.2) (x)\n",
    "\n",
    "# CONV + UPSAMPLING 1\n",
    "\n",
    "x = UpSampling2D(size = (2,2 ))(x)\n",
    "\n",
    "x = concatenate([x,vgg_16.get_layer(\"block5_conv3\").output])\n",
    "\n",
    "x = Conv2D(filters = 256,\n",
    "           kernel_size = (3,3),\n",
    "           kernel_initializer = 'he_uniform',\n",
    "           padding = 'same')(x)\n",
    "\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = Activation(activation = 'relu')(x)\n",
    "\n",
    "x = Dropout(0.2) (x)\n",
    "\n",
    "# CONV + UPSAMPLING 2\n",
    "\n",
    "x = UpSampling2D(size = (2, 2))(x)\n",
    "\n",
    "x = concatenate([x,vgg_16.get_layer(\"block4_conv3\").output])\n",
    "\n",
    "x = Conv2D(filters = 128,\n",
    "           kernel_size = (3,3),\n",
    "           kernel_initializer = 'he_uniform',\n",
    "           padding = 'same')(x)\n",
    "\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = Activation(activation = 'relu')(x)\n",
    "\n",
    "x = Dropout(0.2) (x)\n",
    "\n",
    "# CONV + UPSAMPLING 3\n",
    "\n",
    "x = UpSampling2D(size = (2, 2))(x)\n",
    "\n",
    "x = concatenate([x,vgg_16.get_layer(\"block3_conv3\").output])\n",
    "\n",
    "x = Conv2D(filters = 64,\n",
    "           kernel_size = (3,3),\n",
    "           kernel_initializer = 'he_uniform',\n",
    "           padding = 'same')(x)\n",
    "\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = Activation(activation = 'relu')(x)\n",
    "\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "# CONV + UPSAMPLING 4\n",
    "\n",
    "x = UpSampling2D(size = (2, 2))(x)\n",
    "\n",
    "#x = concatenate([x,vgg_16.get_layer(\"block2_conv3\").output])\n",
    "\n",
    "x = Conv2D(filters = 32,\n",
    "           kernel_size = (3,3),\n",
    "           kernel_initializer = 'he_uniform',\n",
    "           padding = 'same')(x)\n",
    "\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = Activation(activation = 'relu')(x)\n",
    "\n",
    "x = Dropout(0.2) (x)\n",
    "\n",
    "# CONV + UPSAMPLING 5\n",
    "\n",
    "x = UpSampling2D(size = (2, 2))(x)\n",
    "\n",
    "#x = concatenate([x,vgg_16.get_layer(\"block1_conv3\").output])\n",
    "\n",
    "x = Conv2D(filters = 8,\n",
    "           kernel_size = (3,3),\n",
    "           kernel_initializer = 'he_uniform',\n",
    "           padding = 'same')(x)\n",
    "\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = Activation(activation = 'relu')(x)\n",
    "\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "#-----------------------------------------------------------------------------------------------\n",
    "#-----------------------------------------------------------------------------------------------\n",
    "#-----------------------------------------------------------------------------------------------\n",
    "\n",
    "x_out = Activation(activation = 'softmax')(x)\n",
    "\n",
    "vgg_16_new = Model(input = x_in, output = x_out)\n",
    "\n",
    "vgg_16_new.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model name\n",
    "model_name = 'best_model_vgg_8c.h5'\n",
    "result_dir = './results'\n",
    "vgg_16_new.load_weights(os.path.join(result_dir, model_name), by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_dir = \"./data/full_data/test/\"\n",
    "\n",
    "# obtain a list of files in the test directory\n",
    "list_x_test = np.array(sorted(os.listdir(test_dir)))\n",
    "\n",
    "n = 5\n",
    "file_x_original = []\n",
    "for i in range(n):\n",
    "    file_x_original.append(np.array(cv2.imread(os.path.join(test_dir, list_x_test[800+i]), -1))/255)\n",
    "    \n",
    "file_x_original = np.array(file_x_original)\n",
    "print(file_x_original[0].shape)\n",
    "file_y_pred = vgg_16_new.predict(file_x_original[:,1200:2000,:])\n",
    "print('file_y_pred.shape',file_y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#file_y_pred[file_y_pred > 0.3] = 1\n",
    "#file_y_pred[file_y_pred < 0.3] = 0\n",
    "\n",
    "# for i in range(n):\n",
    "#     plt.figure(figsize = (15,12))\n",
    "#     plt.subplot(2,3,1)\n",
    "#     plt.imshow(file_x_original[i,1200:2000,:]); plt.title('original_color')\n",
    "#     plt.subplfile_y_originalot(2,3,2)\n",
    "#     plt.imshow(file_y_original[i,1200:2000,:]); plt.title('original_label')\n",
    "#     plt.subplot(2,3,3)\n",
    "#     plt.imshow(np.argmax(file_y_pred[i], axis=-1)); plt.title('predicted_label')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post Processing - Sameera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_2D = np.array([np.argmax(image, axis=-1) for image in file_y_pred])\n",
    "NN, HH, WW = output_2D.shape\n",
    "\n",
    "print(output_2D.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for q in range(NN):\n",
    "    print (list_x_test[q][:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Pixel Count\n",
    "import pandas as pd\n",
    "\n",
    "tlabel = output_2D[0]\n",
    "cls = np.unique(tlabel)\n",
    "# print(cls)\n",
    "# print(class_labels)\n",
    "unique, counts = np.unique(tlabel, return_counts=True)\n",
    "\n",
    "# d = dict(zip(unique, counts))\n",
    "# class_labels = np.array((33, 34, 35, 36, 38, 39, 40, 0))\n",
    "label_list = np.array((0,1,2,3,4,5,6,7))\n",
    "label_map = dict(zip(label_list, class_labels))\n",
    "print (label_list)\n",
    "print (label_map)\n",
    "print(unique, counts)\n",
    "newList= []\n",
    "for lb in range(len(cls)):\n",
    "    newList.append(label_map[cls[lb]])\n",
    "# print('newlist:',newList)\n",
    "d = dict(zip(newList, counts))\n",
    "print (d)\n",
    "\n",
    "# classdict = {0:'others', 1:'rover', 17:'sky', 33:'car', 34:'motorbicycle', 35:'bicycle', 36:'person', 37:'rider', 38:'truck', 39:'bus', 40:'tricycle', 49:'road', 50:'siderwalk', 65:'traffic_cone'}\n",
    "# df = pd.DataFrame.from_dict(d, orient='index').transpose()\n",
    "# df.rename(columns=classdict, inplace=True)\n",
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To DO List\n",
    "### ImageId,   LabelId, Confidence, Pixel, Count, EncodedPixels\n",
    "### 001bbdb5c4f43bd4dc2b3e3a08b7202a, 33, 300, 1, 0 100|0 100|0 100|\n",
    "\n",
    "1. Find Correct  ImageId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# filelist_x_or[0][:-4]\n",
    "test_dir = os.path.join(\"data/full_data/test\")\n",
    "test_file_paths = os.listdir(test_dir)\n",
    "print(len(test_file_paths))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ImageId = []\n",
    "LabelId = []\n",
    "Confidence = []\n",
    "PixelCount = []\n",
    "EncodedPixels = []\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "print ('WW', WW)\n",
    "for image_id in range(1):\n",
    "    image_id = 4\n",
    "    ## Pixel Count\n",
    "    tlabel = output_2D[image_id]\n",
    "    plt.imshow(tlabel); plt.title('train_label')\n",
    "    plt.show()\n",
    "    print('image dim:', tlabel.shape)\n",
    "    cls = np.unique(tlabel)\n",
    "    unique, counts = np.unique(tlabel, return_counts=True)\n",
    "\n",
    "    label_list = np.array((0,1,2,3,4,5,6,7))\n",
    "    label_map = dict(zip(label_list, class_labels))\n",
    "#     print (label_list)\n",
    "#     print (label_map)\n",
    "#     print(unique, counts)\n",
    "    newList= []\n",
    "    for lb in range(len(cls)):\n",
    "        newList.append(label_map[cls[lb]])\n",
    "    # print('newlist:',newList)\n",
    "    d = dict(zip(newList, counts))\n",
    "    print (d)\n",
    "    \n",
    "    print('\\nimage_id', image_id)\n",
    "    for class_val in range(1):\n",
    "        class_val=5\n",
    "        print('\\nclass:', class_val)\n",
    "        print('\\label_map:', label_map[class_val])\n",
    "        Harr, Warr = np.where(output_2D[image_id] == class_val)\n",
    "        print('Harr',Harr)\n",
    "        print('Warr',Warr)\n",
    "\n",
    "        \n",
    "        confidence = 0\n",
    "        if len(file_y_pred[image_id,Harr,Warr,class_val])!=0:\n",
    "            confidence = np.max(file_y_pred[image_id,Harr,Warr,class_val])\n",
    "            print('confidence', confidence)\n",
    "            row, count = np.unique(Harr, return_counts=True)# for each class\n",
    "\n",
    "            Start = []\n",
    "            mul1 = np.multiply(row, WW)\n",
    "            for st in range(len(row)):\n",
    "                ww2 = Warr[ np.where(Harr==row[st])[0][0] ]\n",
    "                Start.append( mul1[st] + ww2 )\n",
    "            \n",
    "            encodedPix_str = '|'\n",
    "            for tp in range(len(Start)):\n",
    "                encodedPix_str = encodedPix_str + str(Start[tp])+' '+str(Start[tp] + count[tp])+'|'\n",
    "\n",
    "            Image_id = list_x_test[800+image_id][:-4]\n",
    "            ImageId.append(Image_id)\n",
    "            LabelId.append(label_map[class_val])\n",
    "            PixelCount.append(d[label_map[class_val]])\n",
    "            Confidence.append(confidence)\n",
    "            EncodedPixels.append(encodedPix_str)\n",
    "            \n",
    "    #     print('\\nImageId:',ImageId)\n",
    "    #     print('LabelId:',label_map[class_val])\n",
    "    #     print('PixelCount:',d[label_map[class_val]])\n",
    "    #     print('confidence:',confidence)\n",
    "    #     print('EncodedPixels:')\n",
    "    #     print(encodedPix_str)\n",
    "\n",
    "print(\"\\n\\nEND--- %s seconds ---\" % (time.time() - start_time))\n",
    "# per each image - there will be 6 rows in the submission.csv\n",
    "# make the csv\n",
    "pd_columns = ['ImageId','LabelId','PixelCount','Confidence','EncodedPixels']\n",
    "\n",
    "DF = pd.DataFrame(columns=pd_columns)\n",
    "\n",
    "DF['ImageId'] = ImageId\n",
    "DF['LabelId'] = LabelId\n",
    "DF['PixelCount'] = PixelCount\n",
    "DF['Confidence'] = Confidence\n",
    "DF['EncodedPixels'] = EncodedPixels\n",
    "\n",
    "print(DF)\n",
    "\n",
    "#DF.to_csv('submit.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(Warr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "wer=20\n",
    "print(row[wer])\n",
    "QQQ = np.where(Harr==row[wer])\n",
    "print(len(QQQ[0]))\n",
    "print(QQQ[0])\n",
    "print(Harr)\n",
    "print(Warr[   np.where(Harr==row[wer])[0][0]    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Pixel Encoding\n",
    "\n",
    "img_number = 0 # n from NN\n",
    "\n",
    "#These var. will be created for each image (n)\n",
    "encode_0 = []\n",
    "\n",
    "\n",
    "confidance_dict = {}\n",
    "for x in range(8):\n",
    "    confidance_dict[x]=0\n",
    "\n",
    "for h in range(1000):\n",
    "    start = [None,None,None,None,None,None,None,None]\n",
    "    count = [0,0,0,0,0,0,0,0]\n",
    "    \n",
    "    for w in range(3000,4000):\n",
    "        \n",
    "        # go though labels\n",
    "        for lbl in range(len(label_list)-1):\n",
    "            if output_2D[img_number][h][w]==lbl:#pixel with car label detected\n",
    "                #calc. start pixel number for each class\n",
    "                if start[lbl]==None:\n",
    "                    start[lbl] = w\n",
    "                else:\n",
    "                    count[lbl] = count[lbl]+1 # count pixel belong to each class\n",
    "\n",
    "                # get confidence level\n",
    "                lbl_pos = np.argmax(file_y_pred[img_number][h][w])\n",
    "                if (lbl_pos==lbl) and (file_y_pred[img_number][h][w][lbl]>confidance_dict[lbl]):\n",
    "                    confidance_dict[lbl] = file_y_pred[img_number][h][w][lbl]\n",
    "                \n",
    "#     for lbl in range(len(label_list)):\n",
    "    if start[0]!=None:\n",
    "#         print ('h:',h,'  |',start[0]*h,' ',count[0],'|')\n",
    "        encode_0.append([start[0]*h,count[0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Pixel Encoding +++++ BACKUP\n",
    "\n",
    "img_number = 0 # n from NN\n",
    "\n",
    "#These var. will be created for each image (n)\n",
    "encode_0 = []\n",
    "encode_1 = []\n",
    "encode_2 = []\n",
    "encode_3 = []\n",
    "encode_4 = []\n",
    "encode_5 = []\n",
    "encode_6 = []\n",
    "encode_7 = []\n",
    "\n",
    "confidance_dict = {}\n",
    "for x in range(8):\n",
    "    confidance_dict[x]=0\n",
    "\n",
    "for h in range(1000):\n",
    "    start = [None,None,None,None,None,None,None,None]\n",
    "    count = [0,0,0,0,0,0,0,0]\n",
    "    \n",
    "    for w in range(3000,4000):\n",
    "        \n",
    "        # go though labels\n",
    "        for lbl in range(len(label_list)-1):\n",
    "            if output_2D[img_number][h][w]==lbl:#pixel with car label detected\n",
    "                #calc. start pixel number for each class\n",
    "                if start[lbl]==None:\n",
    "                    start[lbl] = w\n",
    "                else:\n",
    "                    count[lbl] = count[lbl]+1 # count pixel belong to each class\n",
    "\n",
    "                # get confidence level\n",
    "                lbl_pos = np.argmax(file_y_pred[img_number][h][w])\n",
    "                if (lbl_pos==lbl) and (file_y_pred[img_number][h][w][lbl]>confidance_dict[lbl]):\n",
    "                    confidance_dict[lbl] = file_y_pred[img_number][h][w][lbl]\n",
    "                \n",
    "#     for lbl in range(len(label_list)):\n",
    "    if start[0]!=None:\n",
    "#         print ('h:',h,'  |',start[0]*h,' ',count[0],'|')\n",
    "        encode_1.append([start[0]*h,count[0]])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(encode)\n",
    "\n",
    "print(confidance_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POst processing END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loss function based on IoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.layers import *\n",
    "import keras.backend as K\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_IoU(y_true, y_pred):\n",
    "    # convert to numpy array for convenience and flatten\n",
    "    pred = K.eval(y_pred)\n",
    "    pred_f = pred.flatten()\n",
    "    truth = K.eval(y_true)\n",
    "    truth_f = truth.flatten()\n",
    "    \n",
    "    out_shape = pred.shape\n",
    "        \n",
    "    IoU = np.zeros(out_shape)\n",
    "    \n",
    "    lbls_in_pred = np.unique(pred_f)\n",
    "    for pr_class in lbls_in_pred:\n",
    "        # create mask of units that predicted pr_class\n",
    "        mask_pr = (pred_f == pr_class)\n",
    "        mask_tr = (truth_f == pr_class)\n",
    "        \n",
    "        # get intersection and union values for pr_class\n",
    "        inter = np.sum(mask_pr == mask_tr)\n",
    "        union = np.sum(mask_pr + mask_tr - inter)\n",
    "        \n",
    "        iou = (inter / union)\n",
    "        \n",
    "        # use value only on units that did the prediction\n",
    "        iou_arr = mask_pr * iou\n",
    "        \n",
    "        # reshape and put in dictionary\n",
    "        IoU += iou_arr.reshape(out_shape)\n",
    "    \n",
    "    IoU *= np.mean(IoU) \n",
    "    return IoU\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred = np.random.randint(0, 6, (300, 300))\n",
    "# truth = np.random.randint(0, 6, (300, 300))\n",
    "\n",
    "pred = np.random.randint(0, 2, (3, 3))\n",
    "print(pred)\n",
    "print()\n",
    "\n",
    "truth = np.ones((3,3))\n",
    "\n",
    "pred = K.variable(pred)\n",
    "truth = K.variable(truth)\n",
    "\n",
    "c = compute_IoU(truth, pred)\n",
    "# i = np.unique(pred)[0]\n",
    "# print(np.min(c), np.max(c))\n",
    "print(c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras.applications.mobilenet as mn\n",
    "c = mn.MobileNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
